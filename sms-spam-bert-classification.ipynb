{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-12T20:28:34.483126Z",
     "start_time": "2024-06-12T20:28:34.442868Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "sms = pd.read_csv(\"preprocessed_sms.csv\", encoding='latin-1')\n",
    "\n",
    "sms['label'] = sms['label'].map({'ham': 0, 'spam': 1})\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(sms['message'], sms['label'], test_size=0.3, random_state=42)"
   ],
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T20:28:36.837315Z",
     "start_time": "2024-06-12T20:28:35.402089Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Токенізація тексту за допомогою BERT Tokenizer\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "# Завантаження токенайзера BERT\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Токенізація тексту\n",
    "train_encodings = tokenizer(list(X_train), truncation=True, padding=True, max_length=128)\n",
    "test_encodings = tokenizer(list(X_test), truncation=True, padding=True, max_length=128)"
   ],
   "id": "6cfa9ab8493d01e9",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T20:30:23.273599Z",
     "start_time": "2024-06-12T20:30:21.337836Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Створення тензорів для міток\n",
    "train_labels = tf.convert_to_tensor(y_train.values)\n",
    "test_labels = tf.convert_to_tensor(y_test.values)\n",
    "\n",
    "# Створення TensorFlow Dataset\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    dict(train_encodings),\n",
    "    train_labels\n",
    ")).shuffle(len(X_train)).batch(16)\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    dict(test_encodings),\n",
    "    test_labels\n",
    ")).batch(16)"
   ],
   "id": "8831dd9be64033d",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T20:30:26.879614Z",
     "start_time": "2024-06-12T20:30:24.726135Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import TFBertForSequenceClassification\n",
    "import tensorflow as tf\n",
    "\n",
    "# Завантаження моделі BERT для класифікації\n",
    "model = TFBertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n",
    "\n",
    "# Налаштування оптимізатора\n",
    "optimizer = tf.keras.optimizers.legacy.Adam(learning_rate=5e-5)\n",
    "\n",
    "# Визначення функції втрат\n",
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "# Компіляція моделі\n",
    "model.compile(optimizer=optimizer, loss=loss_fn, metrics=['accuracy'])"
   ],
   "id": "c7323c8485298cfa",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T21:10:18.874179Z",
     "start_time": "2024-06-12T20:30:28.931365Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Навчання моделі\n",
    "history = model.fit(train_dataset, epochs=3)"
   ],
   "id": "c757f4209c06c673",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "244/244 [==============================] - 840s 3s/step - loss: 0.0807 - accuracy: 0.9756\n",
      "Epoch 2/3\n",
      "244/244 [==============================] - 767s 3s/step - loss: 0.0156 - accuracy: 0.9949\n",
      "Epoch 3/3\n",
      "244/244 [==============================] - 782s 3s/step - loss: 0.0202 - accuracy: 0.9941\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T21:12:36.828965Z",
     "start_time": "2024-06-12T21:12:12.179120Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import datetime\n",
    "\n",
    "timestamp = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "model_filename = f'bert_sms_classifier_{timestamp}'\n",
    "\n",
    "model.save(f'./models/{model_filename}')\n",
    "model.save(f'./models/{model_filename}.h5')"
   ],
   "id": "af424f1347cd7a85",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/bert_sms_classifier_20240613-001212/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/bert_sms_classifier_20240613-001212/assets\n",
      "/Users/m.semitkin/PycharmProjects/NLP-sms-spam/.venv/lib/python3.9/site-packages/tf_keras/src/engine/training.py:3098: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native TF-Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "Saving the model to HDF5 format requires the model to be a Functional model or a Sequential model. It does not work for subclassed models, because such models are defined via the body of a Python method, which isn't safely serializable. Consider saving to the Tensorflow SavedModel format (by setting save_format=\"tf\") or using `save_weights`.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNotImplementedError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[24], line 7\u001B[0m\n\u001B[1;32m      4\u001B[0m model_filename \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mbert_sms_classifier_\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtimestamp\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m      6\u001B[0m model\u001B[38;5;241m.\u001B[39msave(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m./models/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmodel_filename\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m----> 7\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msave\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43mf\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m./models/\u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[43mmodel_filename\u001B[49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[38;5;124;43m.h5\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/NLP-sms-spam/.venv/lib/python3.9/site-packages/tf_keras/src/utils/traceback_utils.py:70\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[1;32m     68\u001B[0m     \u001B[38;5;66;03m# To get the full stack trace, call:\u001B[39;00m\n\u001B[1;32m     69\u001B[0m     \u001B[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001B[39;00m\n\u001B[0;32m---> 70\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m     71\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m     72\u001B[0m     \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[0;32m~/PycharmProjects/NLP-sms-spam/.venv/lib/python3.9/site-packages/tf_keras/src/saving/legacy/save.py:151\u001B[0m, in \u001B[0;36msave_model\u001B[0;34m(model, filepath, overwrite, include_optimizer, save_format, signatures, options, save_traces)\u001B[0m\n\u001B[1;32m    142\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[1;32m    143\u001B[0m     save_format \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mh5\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    144\u001B[0m     \u001B[38;5;129;01mor\u001B[39;00m (h5py \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(filepath, h5py\u001B[38;5;241m.\u001B[39mFile))\n\u001B[1;32m    145\u001B[0m     \u001B[38;5;129;01mor\u001B[39;00m saving_utils\u001B[38;5;241m.\u001B[39mis_hdf5_filepath(filepath)\n\u001B[1;32m    146\u001B[0m ):\n\u001B[1;32m    147\u001B[0m     \u001B[38;5;66;03m# TODO(b/130258301): add utility method for detecting model type.\u001B[39;00m\n\u001B[1;32m    148\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m model\u001B[38;5;241m.\u001B[39m_is_graph_network \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(\n\u001B[1;32m    149\u001B[0m         model, sequential\u001B[38;5;241m.\u001B[39mSequential\n\u001B[1;32m    150\u001B[0m     ):\n\u001B[0;32m--> 151\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mNotImplementedError\u001B[39;00m(\n\u001B[1;32m    152\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mSaving the model to HDF5 format requires the model to be a \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    153\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFunctional model or a Sequential model. It does not work for \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    154\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msubclassed models, because such models are defined via the \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    155\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbody of a Python method, which isn\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt safely serializable. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    156\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mConsider saving to the Tensorflow SavedModel format (by \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    157\u001B[0m             \u001B[38;5;124m'\u001B[39m\u001B[38;5;124msetting save_format=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m) or using `save_weights`.\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m    158\u001B[0m         )\n\u001B[1;32m    159\u001B[0m     hdf5_format\u001B[38;5;241m.\u001B[39msave_model_to_hdf5(\n\u001B[1;32m    160\u001B[0m         model, filepath, overwrite, include_optimizer\n\u001B[1;32m    161\u001B[0m     )\n\u001B[1;32m    162\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "\u001B[0;31mNotImplementedError\u001B[0m: Saving the model to HDF5 format requires the model to be a Functional model or a Sequential model. It does not work for subclassed models, because such models are defined via the body of a Python method, which isn't safely serializable. Consider saving to the Tensorflow SavedModel format (by setting save_format=\"tf\") or using `save_weights`."
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T21:14:32.023905Z",
     "start_time": "2024-06-12T21:14:25.268079Z"
    }
   },
   "cell_type": "code",
   "source": [
    "loaded_model = tf.keras.models.load_model(f'./models/{model_filename}')\n",
    "\n",
    "# Або завантаження моделі у форматі HDF5\n",
    "# loaded_model = tf.keras.models.load_model(f'./models/{model_filename}.h5')\n"
   ],
   "id": "430e9063e550a4c2",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T21:16:13.748226Z",
     "start_time": "2024-06-12T21:14:36.777900Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Прогнозування на тестових даних\n",
    "predictions = loaded_model.predict(test_dataset)"
   ],
   "id": "28e4a27f898211bf",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105/105 [==============================] - 97s 915ms/step\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'logits'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[27], line 5\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;66;03m# Прогнозування на тестових даних\u001B[39;00m\n\u001B[1;32m      4\u001B[0m predictions \u001B[38;5;241m=\u001B[39m loaded_model\u001B[38;5;241m.\u001B[39mpredict(test_dataset)\n\u001B[0;32m----> 5\u001B[0m pred_labels \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39margmax(\u001B[43mpredictions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlogits\u001B[49m, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\u001B[38;5;241m.\u001B[39mnumpy()\n\u001B[1;32m      7\u001B[0m \u001B[38;5;66;03m# Оцінка точності\u001B[39;00m\n\u001B[1;32m      8\u001B[0m accuracy \u001B[38;5;241m=\u001B[39m accuracy_score(y_test, pred_labels)\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'dict' object has no attribute 'logits'"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T21:18:11.545283Z",
     "start_time": "2024-06-12T21:18:11.532164Z"
    }
   },
   "cell_type": "code",
   "source": [
    "pred_labels = tf.argmax(predictions['logits'], axis=1).numpy()\n",
    "\n",
    "accuracy = accuracy_score(y_test, pred_labels)\n",
    "print(f'Accuracy: {accuracy}')"
   ],
   "id": "2f152aa5476d9c34",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9946172248803827\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T21:26:36.398516Z",
     "start_time": "2024-06-12T21:26:36.356581Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, pred_labels, target_names=['ham', 'spam']))"
   ],
   "id": "75eb9b96ab24136c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       1.00      1.00      1.00      1453\n",
      "        spam       0.99      0.97      0.98       219\n",
      "\n",
      "    accuracy                           0.99      1672\n",
      "   macro avg       0.99      0.98      0.99      1672\n",
      "weighted avg       0.99      0.99      0.99      1672\n",
      "\n"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T21:26:36.353191Z",
     "start_time": "2024-06-12T21:26:32.799778Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import gradio as gr\n",
    "\n",
    "def classify_message(message):\n",
    "    inputs = tokenizer(message, return_tensors=\"tf\", truncation=True, padding=True, max_length=128)\n",
    "    test_predictions = loaded_model(inputs)\n",
    "    test_logits = test_predictions['logits']\n",
    "    probabilities = tf.nn.softmax(test_logits, axis=1).numpy()\n",
    "    pred_label = tf.argmax(probabilities, axis=1).numpy()\n",
    "    # label = 'spam' if pred_label[0] == 1 else 'ham'\n",
    "    return {'Ham': probabilities[0][0],\n",
    "            'Spam': probabilities[0][1]}\n",
    "    # return f\"Label: {label}\\nHam Probability: {probabilities[0][0]:.4f}\\nSpam Probability: {probabilities[0][1]:.4f}\"\n",
    "\n",
    "interface = gr.Interface(\n",
    "    fn=classify_message,\n",
    "    inputs=gr.Textbox(lines=2, placeholder=\"Enter SMS message...\"),\n",
    "    outputs=gr.Textbox(),\n",
    "    title=\"SMS Ham/Spam Classifier\",\n",
    "    description=\"Enter an SMS message to classify it as Ham or Spam.\"\n",
    ")\n",
    "\n",
    "interface.launch(debug=True, inbrowser=True)"
   ],
   "id": "801413ae15ed532b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "Thanks for being a Gradio user! If you have questions or feedback, please join our Discord server and chat with us: https://discord.gg/feTf9x3ZSB\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keyboard interruption in main thread... closing server.\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 33
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
